{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/graph/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from utils import (\n",
    "    get_link_labels,\n",
    "    prediction_fairness,\n",
    ")\n",
    "\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric import seed_everything\n",
    "\n",
    "seed_everything(188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected, to_networkx, k_hop_subgraph, is_undirected\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
    "from torch_geometric.seed import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model.gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    make_scorer,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection, pipeline, metrics\n",
    "\n",
    "# Metrics\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    ")\n",
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from training_args import parse_args\n",
    "args=parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = \"citeseer\" #\"cora\" \"pubmed\"\n",
    "path = osp.join(osp.dirname(osp.realpath('__file__')), \"..\", \"data\", dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/FairDrop'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/FairDrop/../data/citeseer'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_seeds = [0,1,2,3,4,5]\n",
    "acc_auc = []\n",
    "fairness = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.in_dim=data.num_features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delta = 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "protected_attribute = data.y\n",
    "Y = torch.LongTensor(protected_attribute).to(device)\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data, val_ratio=0.1, test_ratio=0.2)\n",
    "data = data.to(device)\n",
    "num_classes = len(np.unique(protected_attribute))\n",
    "N = data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtrain_mask = torch.ones(data.train_pos_edge_index.shape[1], dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pos_edge_index = to_undirected(data.train_pos_edge_index)\n",
    "data.train_pos_edge_index = train_pos_edge_index\n",
    "data.dtrain_mask = torch.ones(data.train_pos_edge_index.shape[1], dtype=torch.bool)\n",
    "assert is_undirected(data.train_pos_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=GCN(args)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "best_val_perf = test_perf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.3978, Val: 0.7563, Test: 0.7252\n",
      "Epoch: 200, Loss: 0.3216, Val: 0.8392, Test: 0.8387\n",
      "Epoch: 300, Loss: 0.3022, Val: 0.8459, Test: 0.8523\n",
      "Epoch: 400, Loss: 0.2977, Val: 0.8543, Test: 0.8553\n",
      "Epoch: 500, Loss: 0.2912, Val: 0.8552, Test: 0.8577\n",
      "Epoch: 600, Loss: 0.2839, Val: 0.8612, Test: 0.8590\n",
      "Epoch: 700, Loss: 0.2742, Val: 0.8668, Test: 0.8593\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     link_probs \u001b[38;5;241m=\u001b[39m link_logits\u001b[38;5;241m.\u001b[39msigmoid()\n\u001b[1;32m     35\u001b[0m     link_labels \u001b[38;5;241m=\u001b[39m get_link_labels(pos_edge_index, neg_edge_index)\n\u001b[0;32m---> 36\u001b[0m     auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_probs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     perfs\u001b[38;5;241m.\u001b[39mappend(auc)\n\u001b[1;32m     39\u001b[0m val_perf, tmp_test_perf \u001b[38;5;241m=\u001b[39m perfs\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:627\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    625\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    626\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    636\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    637\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    641\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:389\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mauc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected max_fpr in range (0, 1], got: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m max_fpr)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:101\u001b[0m, in \u001b[0;36mauc\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least 2 points are needed to compute area under curve, but x.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;241m%\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 101\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(dx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(dx \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, 1000):\n",
    "    # TRAINING    \n",
    "    #print(\"epoch\",epoch)\n",
    "    neg_edges_tr = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index,\n",
    "        num_nodes=N,\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1) // 2,\n",
    "    ).to(device)\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z = model(data.x, data.train_pos_edge_index)\n",
    "    link_logits= model.decode(\n",
    "        z, data.train_pos_edge_index, neg_edges_tr\n",
    "    )\n",
    "    tr_labels = get_link_labels(\n",
    "        data.train_pos_edge_index, neg_edges_tr\n",
    "    ).to(device)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, tr_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # EVALUATION\n",
    "    model.eval()\n",
    "    perfs = []\n",
    "    for prefix in [\"val\", \"test\"]:\n",
    "        pos_edge_index = data[f\"{prefix}_pos_edge_index\"]\n",
    "        neg_edge_index = data[f\"{prefix}_neg_edge_index\"]\n",
    "        with torch.no_grad():\n",
    "            z = model(data.x, data.train_pos_edge_index)\n",
    "            link_logits = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "        link_probs = link_logits.sigmoid()\n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "        auc = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
    "        perfs.append(auc)\n",
    "\n",
    "    val_perf, tmp_test_perf = perfs\n",
    "    if val_perf > best_val_perf:\n",
    "        best_val_perf = val_perf\n",
    "        test_perf = tmp_test_perf\n",
    "    if epoch%100==0:\n",
    "        log = \"Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}\"\n",
    "        print(log.format(epoch, loss, best_val_perf, test_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ckpt, os.path.join(args.checkpoint_dir, 'model_final.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix=\"test\"\n",
    "pos_edge_index = data[f\"{prefix}_pos_edge_index\"]\n",
    "neg_edge_index = data[f\"{prefix}_neg_edge_index\"]\n",
    "with torch.no_grad():\n",
    "    z = model(data.x, data.train_pos_edge_index)\n",
    "    link_logits= model.decode(z, pos_edge_index, neg_edge_index)\n",
    "link_probs = link_logits.sigmoid()\n",
    "link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "\n",
    "edge_idx=torch.cat([pos_edge_index, neg_edge_index], dim=-1)\n",
    "\n",
    "auc = test_perf\n",
    "cut = [0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "best_acc = 0\n",
    "best_cut = 0.5\n",
    "for i in cut:\n",
    "    acc = accuracy_score(link_labels.cpu(), link_probs.cpu() >= i)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_cut = i\n",
    "f = prediction_fairness(\n",
    "    edge_idx.cpu(), link_labels.cpu(), link_probs.cpu() >= best_cut, Y.cpu()\n",
    ")\n",
    "acc_auc.append([best_acc * 100, auc * 100])\n",
    "fairness.append([x * 100 for x in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fair_metrics(gt, y, group):\n",
    "    metrics_dict = {\n",
    "        \"DPd\": demographic_parity_difference(gt, y, sensitive_features=group),\n",
    "        \"EOd\": equalized_odds_difference(gt, y, sensitive_features=group),\n",
    "    }\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group=Y.cpu()\n",
    "te_y=link_probs.cpu() >= best_cut\n",
    "test_edge_idx=edge_idx.cpu()\n",
    "test_edge_labels=link_labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "te_dyadic_src = group[test_edge_idx[0]]\n",
    "te_dyadic_dst = group[test_edge_idx[1]]\n",
    "\n",
    "# SUBGROUP DYADIC\n",
    "u = list(combinations_with_replacement(np.unique(group), r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (5, 5)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "te_sub_diatic = []\n",
    "for i, j in zip(te_dyadic_src, te_dyadic_dst):\n",
    "    for k, v in enumerate(u):\n",
    "        if (i, j) == v or (j, i) == v:\n",
    "            te_sub_diatic.append(k)\n",
    "            break\n",
    "te_sub_diatic = np.asarray(te_sub_diatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "te_mixed_dyadic = te_dyadic_src != te_dyadic_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fairlearn.metrics.demographic_parity_difference(y_true, y_pred, *, sensitive_features, method='between_groups', sample_weight=None)\n",
    "Calculate the demographic parity difference.\n",
    "\n",
    "The demographic parity difference is defined as the difference between the largest and the smallest group-level selection rate, \n",
    ", across all values \n",
    " of the sensitive feature(s). The demographic parity difference of 0 means that all groups have the same selection rate.\n",
    "\n",
    "Read more in the User Guide.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "y_true (array-like) – Ground truth (correct) labels.\n",
    "\n",
    "y_pred (array-like) – Predicted labels \n",
    " returned by the classifier.\n",
    "\n",
    "sensitive_features – The sensitive features over which demographic parity should be assessed\n",
    "\n",
    "method (str) – How to compute the differences. See fairlearn.metrics.MetricFrame.difference() for details.\n",
    "\n",
    "sample_weight (array-like) – The sample weights\n",
    "\n",
    "Returns\n",
    ":\n",
    "The demographic parity difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group=Y.cpu()\n",
    "te_y=link_probs.cpu() >= best_cut\n",
    "test_edge_idx=edge_idx.cpu()\n",
    "test_edge_labels=link_labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_dyadic_src = group[test_edge_idx[0]]\n",
    "te_dyadic_dst = group[test_edge_idx[1]]\n",
    "\n",
    "# SUBGROUP DYADIC\n",
    "u = list(combinations_with_replacement(np.unique(group), r=2))\n",
    "\n",
    "te_sub_diatic = []\n",
    "for i, j in zip(te_dyadic_src, te_dyadic_dst):\n",
    "    for k, v in enumerate(u):\n",
    "        if (i, j) == v or (j, i) == v:\n",
    "            te_sub_diatic.append(k)\n",
    "            break\n",
    "te_sub_diatic = np.asarray(te_sub_diatic)\n",
    "# MIXED DYADIC \n",
    "\n",
    "te_mixed_dyadic = te_dyadic_src != te_dyadic_dst\n",
    "# GROUP DYADIC\n",
    "te_gd_dict = fair_metrics(\n",
    "    np.concatenate([test_edge_labels, test_edge_labels], axis=0),\n",
    "    np.concatenate([te_y, te_y], axis=0),\n",
    "    np.concatenate([te_dyadic_src, te_dyadic_dst], axis=0),\n",
    ")\n",
    "\n",
    "te_md_dict = fair_metrics(test_edge_labels, te_y, te_mixed_dyadic)\n",
    "\n",
    "te_sd_dict = fair_metrics(test_edge_labels, te_y, te_sub_diatic)\n",
    "\n",
    "fair_list = [\n",
    "    te_md_dict[\"DPd\"],\n",
    "    te_md_dict[\"EOd\"],\n",
    "    te_gd_dict[\"DPd\"],\n",
    "    te_gd_dict[\"EOd\"],\n",
    "    te_sd_dict[\"DPd\"],\n",
    "    te_sd_dict[\"EOd\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42743364127490735,\n",
       " 0.30759522199684475,\n",
       " 0.18659453511828356,\n",
       " 0.20884312910722247,\n",
       " 0.6431478191093025,\n",
       " 0.6010928961748634]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 101\n",
    "model = GCN(data.num_features, 128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "Y = torch.LongTensor(protected_attribute).to(device)\n",
    "Y_diff = (\n",
    "    Y[data.train_pos_edge_index[0, :]] != Y[data.train_pos_edge_index[1, :]]\n",
    ").to(device)\n",
    "\n",
    "Y_same = (\n",
    "    Y[data.train_pos_edge_index[0, :]] == Y[data.train_pos_edge_index[1, :]]\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 5,  ..., 3, 1, 5], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1706, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Y_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4668, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Y_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff=Y_diff.nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 6369, 6370, 6373], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same=Y_same.nonzero().squeeze()\n",
    "same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_to_delete=100\n",
    "ratio=3\n",
    "diff_size=int(edge_to_delete*(ratio)/(ratio+1))\n",
    "same_size=int(edge_to_delete*(1)/(ratio+1))\n",
    "idx_diff = torch.randperm(diff.shape[0])[:diff_size]\n",
    "df_diff_idx = diff[idx_diff]\n",
    "idx_same = torch.randperm(same.shape[0])[:same_size]\n",
    "df_same_idx = same[idx_same]\n",
    "df_global_idx=torch.cat((df_diff_idx,df_same_idx),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 335, 1389, 1387, 2277, 2125, 2856, 2965, 3766, 1033, 2632,  620, 4441,\n",
       "         861, 1951, 3376, 5056, 1842,  375, 5372, 5927,  922, 4951, 2834, 1451,\n",
       "        4695], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_same_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dr_mask = torch.ones(data.train_pos_edge_index.shape[1], dtype=torch.bool)\n",
    "dr_mask[df_global_idx] = False\n",
    "dr_mask=dr_mask.to(device)\n",
    "\n",
    "df_mask = torch.zeros(data.train_pos_edge_index.shape[1], dtype=torch.bool)\n",
    "df_mask[df_global_idx] = True\n",
    "df_mask=df_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Edges in S_Df\n",
    "_, two_hop_edge, _, two_hop_mask = k_hop_subgraph(\n",
    "        data.train_pos_edge_index[:, df_mask].flatten().unique(), \n",
    "        2, \n",
    "        data.train_pos_edge_index,\n",
    "        num_nodes=data.num_nodes)\n",
    "data.sdf_mask = two_hop_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nodes in S_Df\n",
    "_, one_hop_edge, _, one_hop_mask = k_hop_subgraph(\n",
    "    data.train_pos_edge_index[:, df_mask].flatten().unique(), \n",
    "    1, \n",
    "    data.train_pos_edge_index,\n",
    "    num_nodes=data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf_node_1hop = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "sdf_node_2hop = torch.zeros(data.num_nodes, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf_node_1hop[one_hop_edge.flatten().unique()] = True\n",
    "sdf_node_2hop[two_hop_edge.flatten().unique()] = True\n",
    "assert sdf_node_1hop.sum() == len(one_hop_edge.flatten().unique())\n",
    "assert sdf_node_2hop.sum() == len(two_hop_edge.flatten().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.sdf_node_1hop_mask = sdf_node_1hop\n",
    "data.sdf_node_2hop_mask = sdf_node_2hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    1,  ..., 3324, 3325, 3326],\n",
       "        [ 628,  158,  486,  ..., 2820, 1643,   33]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_pos_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 1, 0, 0], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_hop_mask.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pos_edge_index, [df_mask, two_hop_mask] = to_undirected(data.train_pos_edge_index, [df_mask.int(), two_hop_mask.int()])\n",
    "two_hop_mask = two_hop_mask.bool()\n",
    "df_mask = df_mask.bool()\n",
    "dr_mask = ~df_mask\n",
    "\n",
    "data.train_pos_edge_index = train_pos_edge_index\n",
    "data.edge_index = train_pos_edge_index\n",
    "assert is_undirected(data.train_pos_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.sdf_mask = two_hop_mask\n",
    "data.df_mask = df_mask\n",
    "data.dr_mask = dr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/graph/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.6316, Val: 0.8095, Test: 0.8118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m best_val_perf \u001b[38;5;241m=\u001b[39m test_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# TRAINING    \u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     neg_edges_tr \u001b[38;5;241m=\u001b[39m \u001b[43mnegative_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pos_edge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_neg_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pos_edge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m         keep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(randomization[epoch], Y_aux, \u001b[38;5;241m~\u001b[39mY_aux)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/torch_geometric/utils/negative_sampling.py:97\u001b[0m, in \u001b[0;36mnegative_sampling\u001b[0;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[1;32m     95\u001b[0m idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# Number of tries to sample negative indices.\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     rnd \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(rnd, idx)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m neg_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/torch_geometric/utils/negative_sampling.py:302\u001b[0m, in \u001b[0;36msample\u001b[0;34m(population, k, device)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39marange(population, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/random.py:379\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    377\u001b[0m selected_add \u001b[38;5;241m=\u001b[39m selected\u001b[38;5;241m.\u001b[39madd\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[0;32m--> 379\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[43mrandbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[1;32m    381\u001b[0m         j \u001b[38;5;241m=\u001b[39m randbelow(n)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "delta = 0.16\n",
    "\n",
    "for random_seed in test_seeds:\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    data = dataset[0]\n",
    "    protected_attribute = data.y\n",
    "    data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "    data = train_test_split_edges(data, val_ratio=0.1, test_ratio=0.2)\n",
    "    data = data.to(device)\n",
    "\n",
    "    num_classes = len(np.unique(protected_attribute))\n",
    "    N = data.num_nodes\n",
    "    \n",
    "    \n",
    "    epochs = 101\n",
    "    model = GCN(data.num_features, 128).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    \n",
    "\n",
    "    Y = torch.LongTensor(protected_attribute).to(device)\n",
    "    Y_aux = (\n",
    "        Y[data.train_pos_edge_index[0, :]] != Y[data.train_pos_edge_index[1, :]]\n",
    "    ).to(device)\n",
    "    randomization = (\n",
    "        torch.FloatTensor(epochs, Y_aux.size(0)).uniform_() < 0.5 + delta\n",
    "    ).to(device)\n",
    "    \n",
    "    \n",
    "    best_val_perf = test_perf = 0\n",
    "    for epoch in range(1, epochs):\n",
    "        # TRAINING    \n",
    "        neg_edges_tr = negative_sampling(\n",
    "            edge_index=data.train_pos_edge_index,\n",
    "            num_nodes=N,\n",
    "            num_neg_samples=data.train_pos_edge_index.size(1) // 2,\n",
    "        ).to(device)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            keep = torch.where(randomization[epoch], Y_aux, ~Y_aux)\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        z = model.encode(data.x, data.train_pos_edge_index[:, keep])\n",
    "        link_logits, _ = model.decode(\n",
    "            z, data.train_pos_edge_index[:, keep], neg_edges_tr\n",
    "        )\n",
    "        tr_labels = get_link_labels(\n",
    "            data.train_pos_edge_index[:, keep], neg_edges_tr\n",
    "        ).to(device)\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(link_logits, tr_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # EVALUATION\n",
    "        model.eval()\n",
    "        perfs = []\n",
    "        for prefix in [\"val\", \"test\"]:\n",
    "            pos_edge_index = data[f\"{prefix}_pos_edge_index\"]\n",
    "            neg_edge_index = data[f\"{prefix}_neg_edge_index\"]\n",
    "            with torch.no_grad():\n",
    "                z = model.encode(data.x, data.train_pos_edge_index)\n",
    "                link_logits, edge_idx = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "            link_probs = link_logits.sigmoid()\n",
    "            link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "            auc = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
    "            perfs.append(auc)\n",
    "\n",
    "        val_perf, tmp_test_perf = perfs\n",
    "        if val_perf > best_val_perf:\n",
    "            best_val_perf = val_perf\n",
    "            test_perf = tmp_test_perf\n",
    "        if epoch%10==0:\n",
    "            log = \"Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}\"\n",
    "            print(log.format(epoch, loss, best_val_perf, test_perf))\n",
    "\n",
    "    # FAIRNESS\n",
    "    auc = test_perf\n",
    "    cut = [0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "    best_acc = 0\n",
    "    best_cut = 0.5\n",
    "    for i in cut:\n",
    "        acc = accuracy_score(link_labels.cpu(), link_probs.cpu() >= i)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_cut = i\n",
    "    f = prediction_fairness(\n",
    "        edge_idx.cpu(), link_labels.cpu(), link_probs.cpu() >= best_cut, Y.cpu()\n",
    "    )\n",
    "    acc_auc.append([best_acc * 100, auc * 100])\n",
    "    fairness.append([x * 100 for x in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = np.mean(np.asarray(acc_auc), axis=0)\n",
    "mf = np.mean(np.asarray(fairness), axis=0)\n",
    "\n",
    "sa = np.std(np.asarray(acc_auc), axis=0)\n",
    "sf = np.std(np.asarray(fairness), axis=0)\n",
    "\n",
    "print(f\"ACC: {ma[0]:2f} +- {sa[0]:2f}\")\n",
    "print(f\"AUC: {ma[1]:2f} +- {sa[1]:2f}\")\n",
    "\n",
    "print(f\"DP mix: {mf[0]:2f} +- {sf[0]:2f}\")\n",
    "print(f\"EoP mix: {mf[1]:2f} +- {sf[1]:2f}\")\n",
    "print(f\"DP group: {mf[2]:2f} +- {sf[2]:2f}\")\n",
    "print(f\"EoP group: {mf[3]:2f} +- {sf[3]:2f}\")\n",
    "print(f\"DP sub: {mf[4]:2f} +- {sf[4]:2f}\")\n",
    "print(f\"EoP sub: {mf[5]:2f} +- {sf[5]:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "graph",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "graph (Local)",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
