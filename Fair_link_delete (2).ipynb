{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/graph/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from utils import (\n",
    "    get_link_labels,\n",
    "    prediction_fairness,\n",
    ")\n",
    "\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import wandb\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected, to_networkx, k_hop_subgraph, is_undirected\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
    "from torch_geometric.seed import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model.gcn import GCN\n",
    "from model.deletegcn import GCNDelete\n",
    "from model.Wdeletegcn import WGCNDelete\n",
    "from model.PNNMask import PGNNMask\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    make_scorer,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection, pipeline, metrics\n",
    "\n",
    "# Metrics\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    ")\n",
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric import seed_everything\n",
    "\n",
    "seed_everything(1888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from training_args import parse_args\n",
    "args=parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model.gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = \"citeseer\" #\"cora\" \"pubmed\"\n",
    "path = osp.join(osp.dirname(osp.realpath('__file__')), \"..\", \"data\", dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/FairDrop'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/FairDrop/../data/citeseer'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_seeds = [0,1,2,3,4,5]\n",
    "acc_auc = []\n",
    "fairness = []\n",
    "acc_auc_ori = []\n",
    "fairness_ori = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.in_dim=data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/graph/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "protected_attribute = data.y\n",
    "Y = torch.LongTensor(protected_attribute).to(device)\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data, val_ratio=0.1, test_ratio=0.2)\n",
    "data = data.to(device)\n",
    "num_classes = len(np.unique(protected_attribute))\n",
    "N = data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191.22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6374/100*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Y = torch.LongTensor(protected_attribute).to(device)\n",
    "Y_diff = (\n",
    "    Y[data.train_pos_edge_index[0, :]] != Y[data.train_pos_edge_index[1, :]]\n",
    ").to(device)\n",
    "\n",
    "Y_same = (\n",
    "    Y[data.train_pos_edge_index[0, :]] == Y[data.train_pos_edge_index[1, :]]\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 6370, 6371, 6373], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Y_diff)\n",
    "torch.sum(Y_same)\n",
    "diff=Y_diff.nonzero().squeeze()\n",
    "same=Y_same.nonzero().squeeze()\n",
    "same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_to_delete=100\n",
    "ratio=3\n",
    "diff_size=int(edge_to_delete*(ratio)/(ratio+1))\n",
    "same_size=int(edge_to_delete*(1)/(ratio+1))\n",
    "idx_diff = torch.randperm(diff.shape[0])[:diff_size]\n",
    "df_diff_idx = diff[idx_diff]\n",
    "idx_same = torch.randperm(same.shape[0])[:same_size]\n",
    "df_same_idx = same[idx_same]\n",
    "df_global_idx=torch.cat((df_diff_idx,df_same_idx),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dr_mask = torch.ones(data.train_pos_edge_index.shape[1], dtype=torch.bool)\n",
    "dr_mask[df_global_idx] = False\n",
    "dr_mask=dr_mask.to(device)\n",
    "\n",
    "df_mask = torch.zeros(data.train_pos_edge_index.shape[1], dtype=torch.bool)\n",
    "df_mask[df_global_idx] = True\n",
    "df_mask=df_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6374])\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "full_pos_edge_index=data.train_pos_edge_index\n",
    "print(full_pos_edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_undirected(full_pos_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##random add edges\n",
    "\n",
    "for target in range(edge_to_delete):\n",
    "    _, l_hop_edge, _, l_hop_mask = k_hop_subgraph(\n",
    "            [data.train_pos_edge_index[:, df_mask][0,:][target]], \n",
    "            1, \n",
    "            data.train_pos_edge_index,\n",
    "            num_nodes=data.num_nodes)\n",
    "\n",
    "    ldset1=l_hop_edge.flatten().unique()\n",
    "    ldset1=ldset1[ldset1!=data.train_pos_edge_index[:, df_mask][0,:][target].item()]\n",
    "\n",
    "    _, r_hop_edge, _, r_hop_mask = k_hop_subgraph(\n",
    "            [data.train_pos_edge_index[:, df_mask][1,:][target]], \n",
    "            1, \n",
    "            data.train_pos_edge_index,\n",
    "            num_nodes=data.num_nodes)\n",
    "\n",
    "    rdset1=r_hop_edge.flatten().unique()\n",
    "    rdset1=rdset1[rdset1!=data.train_pos_edge_index[:, df_mask][1,:][target].item()]\n",
    "\n",
    "    combine = list(product(ldset1.tolist(), rdset1.tolist()))\n",
    "    ind=[True if Y[a[0]]!=Y[a[1]] else False for a in combine ]\n",
    "    sele_pair=[combine[i] for i in range(len(ind)) if ind[i]==True]\n",
    "    n=len(sele_pair)\n",
    "    if(n>0):\n",
    "        add=min(n,2)\n",
    "        add_pair_ind=torch.randperm(len(sele_pair))[:add]\n",
    "        add_pair=[sele_pair[i] for i in add_pair_ind]\n",
    "        add_matrix_0=[add_pair[i][0] for i in range(len(add_pair))] \n",
    "        add_matrix_1=[add_pair[i][1] for i in range(len(add_pair))] \n",
    "        add_matrix1=torch.tensor([add_matrix_0,add_matrix_1]).to(device)\n",
    "        add_matrix2=torch.tensor([add_matrix_1,add_matrix_0]).to(device)\n",
    "        full_pos_edge_index=torch.cat((full_pos_edge_index,add_matrix1),1)\n",
    "        full_pos_edge_index=torch.cat((full_pos_edge_index,add_matrix2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6374])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_pos_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.full_pos_edge_index=full_pos_edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the graph to undirected graph and prepare the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dr_full_mask = torch.ones(data.full_pos_edge_index.shape[1], dtype=torch.bool)\n",
    "dr_full_mask[df_global_idx] = False\n",
    "dr_full_mask=dr_full_mask.to(device)\n",
    "\n",
    "df_full_mask = torch.zeros(data.full_pos_edge_index.shape[1], dtype=torch.bool)\n",
    "df_full_mask[df_global_idx] = True\n",
    "df_full_mask=df_full_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6684])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.full_pos_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Edges in S_Df\n",
    "_, two_hop_edge, _, two_hop_mask = k_hop_subgraph(\n",
    "        data.full_pos_edge_index[:, df_full_mask].flatten().unique(), \n",
    "        2, \n",
    "        data.full_pos_edge_index,\n",
    "        num_nodes=data.num_nodes)\n",
    "data.sdf_mask = two_hop_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nodes in S_Df\n",
    "_, one_hop_edge, _, one_hop_mask = k_hop_subgraph(\n",
    "    data.full_pos_edge_index[:, df_full_mask].flatten().unique(), \n",
    "    1, \n",
    "    data.full_pos_edge_index,\n",
    "    num_nodes=data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf_node_1hop = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "sdf_node_2hop = torch.zeros(data.num_nodes, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf_node_1hop[one_hop_edge.flatten().unique()] = True\n",
    "sdf_node_2hop[two_hop_edge.flatten().unique()] = True\n",
    "assert sdf_node_1hop.sum() == len(one_hop_edge.flatten().unique())\n",
    "assert sdf_node_2hop.sum() == len(two_hop_edge.flatten().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.sdf_node_1hop_mask = sdf_node_1hop\n",
    "data.sdf_node_2hop_mask = sdf_node_2hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_pos_edge_index1, [df_full_mask1, two_hop_mask1] = to_undirected(data.full_pos_edge_index, [df_full_mask.int(), two_hop_mask.int()])\n",
    "two_hop_mask1 = two_hop_mask1.bool()\n",
    "df_full_mask1 = df_full_mask1.bool()\n",
    "dr_full_mask1 = ~df_full_mask\n",
    "\n",
    "data.full_pos_edge_index1 =full_pos_edge_index1\n",
    "data.edge_index1 = full_pos_edge_index1\n",
    "assert is_undirected(data.full_pos_edge_index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.sdf_mask = two_hop_mask1\n",
    "data.df_full_mask = df_full_mask1\n",
    "data.dr_full_mask = dr_full_mask1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learnable edge weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(3703, 128)\n",
       "  (conv2): GCNConv(128, 64)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt = torch.load(os.path.join(args.checkpoint_dir, 'model_final.pt'), map_location=device)\n",
    "model_ori=GCN(args)\n",
    "model_ori.load_state_dict(model_ckpt['model_state'], strict=False)\n",
    "model_ori=model_ori.to(device)\n",
    "model_ori.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3327, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ori= model_ori(data.x, data.full_pos_edge_index1[:, data.sdf_mask],return_all_emb=False)\n",
    "z_ori.detach()\n",
    "z_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = PGNNMask(data.x.cuda(), n_hidden=64, temperature=1).to(device)\n",
    "mask=mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer_mask = torch.optim.Adam(mask.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = WGCNDelete(args, sdf_node_1hop, sdf_node_2hop, num_nodes=data.num_nodes, num_edge_type=args.num_edge_type)\n",
    "model_ckpt = torch.load(os.path.join(args.checkpoint_dir, 'model_final.pt'), map_location=device)\n",
    "model.load_state_dict(model_ckpt['model_state'], strict=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters_to_optimize ['deletion1.deletion_weight', 'deletion2.deletion_weight']\n"
     ]
    }
   ],
   "source": [
    "parameters_to_optimize = [\n",
    "                {'params': [p for n, p in model.named_parameters() if 'del' in n], 'weight_decay': 0.0}\n",
    "            ]\n",
    "print('parameters_to_optimize', [n for n, p in model.named_parameters() if 'del' in n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer_mlp = torch.optim.Adam(parameters_to_optimize, lr=0.00001)#, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf1_all_pair_mask = torch.zeros(data.num_nodes, data.num_nodes, dtype=torch.bool)\n",
    "idx = torch.combinations(torch.arange(data.num_nodes)[data.sdf_node_1hop_mask], with_replacement=True).t()\n",
    "sdf1_all_pair_mask[idx[0], idx[1]] = True\n",
    "sdf1_all_pair_mask[idx[1], idx[0]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert sdf1_all_pair_mask.sum().cpu() == data.sdf_node_1hop_mask.sum().cpu() * data.sdf_node_1hop_mask.sum().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " ## Remove Df itself\n",
    "sdf1_all_pair_mask[data.full_pos_edge_index1[:, data.df_full_mask][0], data.full_pos_edge_index1[:, data.df_full_mask][1]] = False\n",
    "sdf1_all_pair_mask[data.full_pos_edge_index1[:, data.df_full_mask][1], data.full_pos_edge_index1[:, data.df_full_mask][0]] = False\n",
    "##sdf1_all_pair_mask contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf2_all_pair_mask = torch.zeros(data.num_nodes, data.num_nodes, dtype=torch.bool)\n",
    "idx = torch.combinations(torch.arange(data.num_nodes)[data.sdf_node_2hop_mask], with_replacement=True).t()\n",
    "sdf2_all_pair_mask[idx[0], idx[1]] = True\n",
    "sdf2_all_pair_mask[idx[1], idx[0]] = True\n",
    "assert sdf2_all_pair_mask.sum().cpu() == data.sdf_node_2hop_mask.sum().cpu() * data.sdf_node_2hop_mask.sum().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Remove Df itself\n",
    "sdf2_all_pair_mask[data.full_pos_edge_index1[:, data.df_full_mask][0], data.full_pos_edge_index1[:, data.df_full_mask][1]] = False\n",
    "sdf2_all_pair_mask[data.full_pos_edge_index1[:, data.df_full_mask][1], data.full_pos_edge_index1[:, data.df_full_mask][0]] = False\n",
    "##sdf1_all_pair_mask contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Lower triangular mask\n",
    "idx = torch.tril_indices(data.num_nodes, data.num_nodes, -1)\n",
    "lower_mask = torch.zeros(data.num_nodes, data.num_nodes, dtype=torch.bool)\n",
    "lower_mask[idx[0], idx[1]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## The final mask is the intersection\n",
    "sdf1_all_pair_without_df_mask = sdf1_all_pair_mask & lower_mask\n",
    "sdf2_all_pair_without_df_mask = sdf2_all_pair_mask & lower_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], val_pos_edge_index=[2, 455], test_pos_edge_index=[2, 910], train_pos_edge_index=[2, 6374], train_neg_adj_mask=[3327, 3327], val_neg_edge_index=[2, 455], test_neg_edge_index=[2, 910], full_pos_edge_index=[2, 6684], sdf_mask=[6470], sdf_node_1hop_mask=[3327], sdf_node_2hop_mask=[3327], full_pos_edge_index1=[2, 6470], edge_index1=[2, 6470], df_full_mask=[6470], dr_full_mask=[6684])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_df_node_mask = torch.ones(data.x.shape[0], dtype=torch.bool, device=data.x.device)\n",
    "non_df_node_mask[data.full_pos_edge_index1[:,data.df_full_mask].flatten().unique()] = False\n",
    "\n",
    "data.sdf_node_1hop_mask_non_df_mask = data.sdf_node_1hop_mask.to(device) & non_df_node_mask\n",
    "data.sdf_node_2hop_mask_non_df_mask = data.sdf_node_2hop_mask.to(device) & non_df_node_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fct = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_ori= model_ori(data.x, data.full_pos_edge_index1[:, data.sdf_mask],return_all_emb=False)\n",
    "logits_ori=(z_ori @ z_ori.t())\n",
    "logits_ori=logits_ori.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neg_size = data.df_full_mask.sum()\n",
    "neg_edge = negative_sampling(\n",
    "    edge_index=data.full_pos_edge_index1,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=neg_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_val(model,weight):\n",
    "    model.eval()\n",
    "    weight.detach()\n",
    "    perfs = []\n",
    "    for prefix in [\"val\", \"test\"]:\n",
    "        pos_edge_index = data[f\"{prefix}_pos_edge_index\"]\n",
    "        neg_edge_index = data[f\"{prefix}_neg_edge_index\"]\n",
    "        with torch.no_grad():\n",
    "            z = model(data.x, data.full_pos_edge_index1,weight)\n",
    "            link_logits = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "        link_probs = link_logits.sigmoid()\n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "        auc = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
    "        perfs.append(auc)\n",
    "    return perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_forget(model,weight):\n",
    "    model.eval()\n",
    "    weight.detach()\n",
    "    neg_edge_index=data.full_pos_edge_index1[:,data.df_full_mask]\n",
    "    pos_edge_index=data.full_pos_edge_index1[:,same[torch.randperm(same.shape[0])[:edge_to_delete]]]\n",
    "    with torch.no_grad():\n",
    "        z = model(data.x, data.full_pos_edge_index1,weight)\n",
    "        link_logits = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "    link_probs = link_logits.sigmoid()\n",
    "    link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "    auc = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
    "    return auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt = {\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer_mlp.state_dict(),\n",
    "        }\n",
    "best_forget=1\n",
    "best_auc=0\n",
    "select=\"forget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6470])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.full_pos_edge_index1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6470])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sdf_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 0, 'train_loss': 6.146191596984863, 'loss_r': 0.34305331110954285, 'loss_l': 0.03359745070338249, 'loss_size': 1.9446946382522583}\n",
      "val 0.7465716700881535 test 0.7193134887090931\n",
      "forget 0.6660999999999999\n",
      "{'Epoch': 100, 'train_loss': 6.006510257720947, 'loss_r': 0.18785344064235687, 'loss_l': 0.033580198884010315, 'loss_size': 1.9446946382522583}\n",
      "val 0.7489288733244777 test 0.7216966549933583\n",
      "forget 0.7056000000000001\n",
      "{'Epoch': 200, 'train_loss': 6.053574562072754, 'loss_r': 0.24014875292778015, 'loss_l': 0.03356415033340454, 'loss_size': 1.9446946382522583}\n",
      "val 0.747716459364811 test 0.7214847240671416\n",
      "forget 0.6542999999999999\n",
      "savebyforget\n",
      "{'Epoch': 300, 'train_loss': 6.041684627532959, 'loss_r': 0.2269379049539566, 'loss_l': 0.033563654869794846, 'loss_size': 1.9446946382522583}\n",
      "val 0.7478782755705832 test 0.7224091293322064\n",
      "forget 0.7245999999999999\n",
      "{'Epoch': 400, 'train_loss': 6.05255651473999, 'loss_r': 0.2390197068452835, 'loss_l': 0.03354578837752342, 'loss_size': 1.9446946382522583}\n",
      "val 0.7469894940224611 test 0.7227551020408163\n",
      "forget 0.70765\n",
      "{'Epoch': 500, 'train_loss': 6.203067302703857, 'loss_r': 0.4062507450580597, 'loss_l': 0.03357823193073273, 'loss_size': 1.9446946382522583}\n",
      "val 0.7426711749788673 test 0.719891317473735\n",
      "forget 0.70465\n",
      "{'Epoch': 600, 'train_loss': 5.972583770751953, 'loss_r': 0.15016067028045654, 'loss_l': 0.03354978933930397, 'loss_size': 1.9446946382522583}\n",
      "val 0.7410868252626495 test 0.7197180292235237\n",
      "forget 0.7132999999999999\n",
      "{'Epoch': 700, 'train_loss': 6.068241596221924, 'loss_r': 0.2564552426338196, 'loss_l': 0.03347620368003845, 'loss_size': 1.9446946382522583}\n",
      "val 0.7412099987924163 test 0.7196636879603913\n",
      "forget 0.6814\n",
      "{'Epoch': 800, 'train_loss': 5.991677284240723, 'loss_r': 0.17137958109378815, 'loss_l': 0.03351496532559395, 'loss_size': 1.9446946382522583}\n",
      "val 0.7406086221470838 test 0.7178160850138873\n",
      "forget 0.70725\n",
      "{'Epoch': 900, 'train_loss': 6.004264831542969, 'loss_r': 0.18536750972270966, 'loss_l': 0.03349968418478966, 'loss_size': 1.9446946382522583}\n",
      "val 0.7419611158072696 test 0.7193303948798455\n",
      "forget 0.7362499999999998\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    adj_sampled,adj_logits = mask(z_ori.cuda())\n",
    "    weight_mask=adj_sampled[data.full_pos_edge_index1[0],data.full_pos_edge_index1[1]]\n",
    "    weight=torch.ones(data.full_pos_edge_index1.shape[1]).to(device)-weight_mask\n",
    "    z = model(data.x, data.full_pos_edge_index1,weight)\n",
    "    neg_size = data.df_full_mask.sum()\n",
    "    neg_edge_index = negative_sampling(\n",
    "    edge_index=data.full_pos_edge_index1,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=neg_size)\n",
    "    df_logits = model.decode(z, data.full_pos_edge_index1[:, data.df_full_mask], neg_edge_index)\n",
    "    loss_size=torch.sum(weight_mask)\n",
    "    loss_r = loss_fct(df_logits[:neg_size], df_logits[neg_size:])\n",
    "    if sdf2_all_pair_without_df_mask.sum() != 0:\n",
    "        logits_sdf = (z @ z.t())[sdf2_all_pair_without_df_mask].sigmoid()\n",
    "        loss_l = loss_fct(logits_sdf, logits_ori[sdf2_all_pair_without_df_mask].sigmoid())\n",
    "    alpha = 0.9\n",
    "    beta=3\n",
    "    loss = alpha * loss_r + (1 - alpha) * loss_l+beta*loss_size\n",
    "    loss.backward(retain_graph=True)\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "    optimizer_mlp.step()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    optimizer_mask.step()\n",
    "    optimizer_mask.zero_grad()\n",
    "    \n",
    "    step_log = {\n",
    "        'Epoch': epoch,\n",
    "        'train_loss': loss.item(),\n",
    "        'loss_r': loss_r.item(),\n",
    "        'loss_l': loss_l.item(),\n",
    "        'loss_size': loss_size.item(),\n",
    "    }\n",
    "\n",
    "    if(epoch%100==0):\n",
    "        print(step_log)\n",
    "    if(epoch%100==0):\n",
    "        p=eval_val(model,weight)\n",
    "        val_perf, tmp_test_perf = p\n",
    "        print(\"val\",val_perf,\"test\",tmp_test_perf)\n",
    "        auc_forget=eval_forget(model,weight)\n",
    "        print(\"forget\",auc_forget)\n",
    "        #print(\"best_forget\",best_forget)\n",
    "        if(select==\"forget\"):\n",
    "            if(auc_forget<best_forget):\n",
    "                best_forget=auc_forget\n",
    "                ckpt = {\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer_mlp.state_dict(),\n",
    "            }\n",
    "                torch.save(ckpt, os.path.join(args.checkpoint_dir, 'model_delete.pt'))\n",
    "                print(\"savebyforget\")\n",
    "        else:\n",
    "            if(tmp_test_perf>best_auc):\n",
    "                tmp_test_perf>best_auc\n",
    "                best_auc=tmp_test_perf\n",
    "                ckpt = {\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "            }\n",
    "                #torch.save(ckpt, os.path.join(args.checkpoint_dir, 'model_delete.pt'))\n",
    "                print(\"savebyauc\")\n",
    "    #wandb.log(step_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6684])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pos_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 95, 822], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pos_edge_index[:,199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 95, 822], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_pos_edge_index[:,199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 1, 0, 0], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_hop_mask.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pos_edge_index, [df_mask, two_hop_mask] = to_undirected(data.train_pos_edge_index, [df_mask.int(), two_hop_mask.int()])\n",
    "two_hop_mask = two_hop_mask.bool()\n",
    "df_mask = df_mask.bool()\n",
    "dr_mask = ~df_mask\n",
    "\n",
    "data.train_pos_edge_index = train_pos_edge_index\n",
    "data.edge_index = train_pos_edge_index\n",
    "assert is_undirected(data.train_pos_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.sdf_mask = two_hop_mask\n",
    "data.df_mask = df_mask\n",
    "data.dr_mask = dr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/graph/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.6316, Val: 0.8095, Test: 0.8118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m best_val_perf \u001b[38;5;241m=\u001b[39m test_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# TRAINING    \u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     neg_edges_tr \u001b[38;5;241m=\u001b[39m \u001b[43mnegative_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pos_edge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_neg_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pos_edge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m         keep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(randomization[epoch], Y_aux, \u001b[38;5;241m~\u001b[39mY_aux)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/torch_geometric/utils/negative_sampling.py:97\u001b[0m, in \u001b[0;36mnegative_sampling\u001b[0;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[1;32m     95\u001b[0m idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# Number of tries to sample negative indices.\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     rnd \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(rnd, idx)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m neg_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/site-packages/torch_geometric/utils/negative_sampling.py:302\u001b[0m, in \u001b[0;36msample\u001b[0;34m(population, k, device)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39marange(population, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.8/random.py:379\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    377\u001b[0m selected_add \u001b[38;5;241m=\u001b[39m selected\u001b[38;5;241m.\u001b[39madd\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[0;32m--> 379\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[43mrandbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[1;32m    381\u001b[0m         j \u001b[38;5;241m=\u001b[39m randbelow(n)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "delta = 0.16\n",
    "\n",
    "for random_seed in test_seeds:\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    data = dataset[0]\n",
    "    protected_attribute = data.y\n",
    "    data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "    data = train_test_split_edges(data, val_ratio=0.1, test_ratio=0.2)\n",
    "    data = data.to(device)\n",
    "\n",
    "    num_classes = len(np.unique(protected_attribute))\n",
    "    N = data.num_nodes\n",
    "    \n",
    "    \n",
    "    epochs = 101\n",
    "    model = GCN(data.num_features, 128).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    \n",
    "\n",
    "    Y = torch.LongTensor(protected_attribute).to(device)\n",
    "    Y_aux = (\n",
    "        Y[data.train_pos_edge_index[0, :]] != Y[data.train_pos_edge_index[1, :]]\n",
    "    ).to(device)\n",
    "    randomization = (\n",
    "        torch.FloatTensor(epochs, Y_aux.size(0)).uniform_() < 0.5 + delta\n",
    "    ).to(device)\n",
    "    \n",
    "    \n",
    "    best_val_perf = test_perf = 0\n",
    "    for epoch in range(1, epochs):\n",
    "        # TRAINING    \n",
    "        neg_edges_tr = negative_sampling(\n",
    "            edge_index=data.train_pos_edge_index,\n",
    "            num_nodes=N,\n",
    "            num_neg_samples=data.train_pos_edge_index.size(1) // 2,\n",
    "        ).to(device)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            keep = torch.where(randomization[epoch], Y_aux, ~Y_aux)\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        z = model.encode(data.x, data.train_pos_edge_index[:, keep])\n",
    "        link_logits, _ = model.decode(\n",
    "            z, data.train_pos_edge_index[:, keep], neg_edges_tr\n",
    "        )\n",
    "        tr_labels = get_link_labels(\n",
    "            data.train_pos_edge_index[:, keep], neg_edges_tr\n",
    "        ).to(device)\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(link_logits, tr_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # EVALUATION\n",
    "        model.eval()\n",
    "        perfs = []\n",
    "        for prefix in [\"val\", \"test\"]:\n",
    "            pos_edge_index = data[f\"{prefix}_pos_edge_index\"]\n",
    "            neg_edge_index = data[f\"{prefix}_neg_edge_index\"]\n",
    "            with torch.no_grad():\n",
    "                z = model.encode(data.x, data.train_pos_edge_index)\n",
    "                link_logits, edge_idx = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "            link_probs = link_logits.sigmoid()\n",
    "            link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "            auc = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
    "            perfs.append(auc)\n",
    "\n",
    "        val_perf, tmp_test_perf = perfs\n",
    "        if val_perf > best_val_perf:\n",
    "            best_val_perf = val_perf\n",
    "            test_perf = tmp_test_perf\n",
    "        if epoch%10==0:\n",
    "            log = \"Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}\"\n",
    "            print(log.format(epoch, loss, best_val_perf, test_perf))\n",
    "\n",
    "    # FAIRNESS\n",
    "    auc = test_perf\n",
    "    cut = [0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "    best_acc = 0\n",
    "    best_cut = 0.5\n",
    "    for i in cut:\n",
    "        acc = accuracy_score(link_labels.cpu(), link_probs.cpu() >= i)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_cut = i\n",
    "    f = prediction_fairness(\n",
    "        edge_idx.cpu(), link_labels.cpu(), link_probs.cpu() >= best_cut, Y.cpu()\n",
    "    )\n",
    "    acc_auc.append([best_acc * 100, auc * 100])\n",
    "    fairness.append([x * 100 for x in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = np.mean(np.asarray(acc_auc), axis=0)\n",
    "mf = np.mean(np.asarray(fairness), axis=0)\n",
    "\n",
    "sa = np.std(np.asarray(acc_auc), axis=0)\n",
    "sf = np.std(np.asarray(fairness), axis=0)\n",
    "\n",
    "print(f\"ACC: {ma[0]:2f} +- {sa[0]:2f}\")\n",
    "print(f\"AUC: {ma[1]:2f} +- {sa[1]:2f}\")\n",
    "\n",
    "print(f\"DP mix: {mf[0]:2f} +- {sf[0]:2f}\")\n",
    "print(f\"EoP mix: {mf[1]:2f} +- {sf[1]:2f}\")\n",
    "print(f\"DP group: {mf[2]:2f} +- {sf[2]:2f}\")\n",
    "print(f\"EoP group: {mf[3]:2f} +- {sf[3]:2f}\")\n",
    "print(f\"DP sub: {mf[4]:2f} +- {sf[4]:2f}\")\n",
    "print(f\"EoP sub: {mf[5]:2f} +- {sf[5]:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "graph",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "graph (Local)",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
